{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic classifier over bag of words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect dataset\n",
    "Resources:\n",
    "- [Wikiquote: Taras Hryhorovych Shevchenko](https://uk.wikiquote.org/wiki/%D0%A8%D0%B5%D0%B2%D1%87%D0%B5%D0%BD%D0%BA%D0%BE_%D0%A2%D0%B0%D1%80%D0%B0%D1%81_%D0%93%D1%80%D0%B8%D0%B3%D0%BE%D1%80%D0%BE%D0%B2%D0%B8%D1%87)\n",
    "- [Wikiquote: Aleksandr Sergeyevich Pushkin](https://ru.wikiquote.org/wiki/%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80_%D0%A1%D0%B5%D1%80%D0%B3%D0%B5%D0%B5%D0%B2%D0%B8%D1%87_%D0%9F%D1%83%D1%88%D0%BA%D0%B8%D0%BD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    (\"В своїй хаті своя й правда, і сила, і воля.\", \"ua\"),\n",
    "    (\"Якби ви вчились так, як треба, то й мудрость би була своя.\", \"ua\"),\n",
    "    (\"Учітесь, читайте, і чужому научайтесь, й свого не цурайтесь.\", \"ua\"),\n",
    "    (\"Обніміте ж, брати мої, найменшого брата.\", \"ua\"),\n",
    "    (\"І на оновленій землі врага не буде, супостата, а буде син, і буде мати, і будуть люде на землі.\", \"ua\"),\n",
    "    (\"І ми не ми, і я не я.\", \"ua\"),\n",
    "    (\"І премудрих немудрі одурять.\", \"ua\"),\n",
    "    (\"Кайданами міняються, правдою торгують.\", \"ua\"),\n",
    "    (\"Караюсь, мучуся… але не каюсь.\", \"ua\"),\n",
    "    (\"Ми просто йшли; у нас нема зерна неправди за собою.\", \"ua\"),\n",
    "    (\"Велике щастя буть вольним чоловіком: робиш, що хочеш, ніхто тебе не спинить.\", \"ua\"),\n",
    "    (\"Це правда, що окроме Бога і чорта в душі нашій єсть ще щось таке, таке страшне, що аж холод іде по серцеві, як хоч трошки його розкриєш\", \"ua\"),\n",
    "    (\"Хто не журиться, не плаче, то той ніколи й не радіє.\", \"ua\"),\n",
    "    (\"Лучше любить і робить, аніж писать і говорить.\", \"ua\"),\n",
    "    (\"Мати, всюди однакова мати.\", \"ua\"),\n",
    "    \n",
    "    \n",
    "    \n",
    "    (\"Вдохновение — это умение приводить себя в рабочее состояние.\", \"ru\"),\n",
    "    (\"Во всяком случае, в аду будет много хорошеньких, там можно будет играть в шарады.\", \"ru\"),\n",
    "    (\"Должно стараться иметь большинство на своей стороне: не оскорбляйте же глупцов.\", \"ru\"),\n",
    "    (\"Желудок просвещенного человека имеет лучшие качества доброго сердца: чувствительность и благодарность.\", \"ru\"),\n",
    "    (\"Зависть — сестра соревнования, следственно из хорошего роду.\", \"ru\"),\n",
    "    (\"Зачем кусать нам груди кормилицы нашей; потому что зубки прорезались?\", \"ru\"),\n",
    "    (\"Злы только дураки и дети.\", \"ru\"),\n",
    "    (\"Не откладывай до ужина того, что можешь съесть за обедом.\", \"ru\"),\n",
    "    (\"Не приведи Бог видеть русский бунт, бессмысленный и беспощадный!\", \"ru\"),\n",
    "    (\"Нет ничего безвкуснее долготерпения и самоотверженности.\", \"ru\"),\n",
    "    (\"Первая любовь всегда является делом чувствительности.\", \"ru\"),\n",
    "    (\"Поэзия выше нравственности — или по крайней мере совсем иное дело.\", \"ru\"),\n",
    "    (\"Поэзия, прости господи, должна быть глуповата.\", \"ru\"),\n",
    "    (\"Разберись, кто прав, кто виноват, да обоих и накажи.\", \"ru\"),\n",
    "    (\"Точность — вежливость поваров.\", \"ru\"),\n",
    "]\n",
    "\n",
    "test = [\n",
    "    (\"Так от, бач, живу, учусь, нікому не кланяюсь і нікого не боюсь, окроме Бога.\", \"ua\"),\n",
    "    (\"Коли мене неволя і горе не побороло, то сам я не звалюся.\", \"ua\"),\n",
    "    (\"Пустив я їх у люди, а до ції пори ще ніхто й спасибі не сказав.\", \"ua\"),\n",
    "    (\"Бачиш, у мене давно вже думка заворушилась перевести його, те слово, на наш милий, на наш любий український язик.\", \"ua\"),\n",
    "    (\"Я читаю його без вивчення, щодня і щогодини.\", \"ua\"),\n",
    "    \n",
    "    (\"Они нужны в некоторых только случаях, но и тут можно без них обойтись, а они привыкли всюду соваться.\", \"ru\"),\n",
    "    (\"Я пишу для себя, а печатаю для денег.\", \"ru\"),\n",
    "    (\"В некотором азиатском народе мужчины каждый день, восстав от сна, благодарят Бога, создавшего их не женщинами.\", \"ru\"),\n",
    "    (\"Разве у хорошеньких женщин должен быть характер?\", \"ru\"),\n",
    "    (\"Европа в отношении к России всегда была столь же невежественна, как и неблагодарна.\", \"ru\"),\n",
    "]\n",
    "\n",
    "targets = [\"ua\", \"ru\"]\n",
    "target_values = {l: i for i, l in enumerate(targets)}\n",
    "random.shuffle(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r\"[^\\w ]\", \"\", sentence)\n",
    "    tokens = sentence.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['так', 'от', 'бач', 'живу', 'учусь', 'нікому', 'не', 'кланяюсь', 'і', 'нікого', 'не', 'боюсь', 'окроме', 'бога']\n",
      "['коли', 'мене', 'неволя', 'і', 'горе', 'не', 'побороло', 'то', 'сам', 'я', 'не', 'звалюся']\n",
      "['пустив', 'я', 'їх', 'у', 'люди', 'а', 'до', 'ції', 'пори', 'ще', 'ніхто', 'й', 'спасибі', 'не', 'сказав']\n",
      "['бачиш', 'у', 'мене', 'давно', 'вже', 'думка', 'заворушилась', 'перевести', 'його', 'те', 'слово', 'на', 'наш', 'милий', 'на', 'наш', 'любий', 'український', 'язик']\n",
      "['я', 'читаю', 'його', 'без', 'вивчення', 'щодня', 'і', 'щогодини']\n",
      "['они', 'нужны', 'в', 'некоторых', 'только', 'случаях', 'но', 'и', 'тут', 'можно', 'без', 'них', 'обойтись', 'а', 'они', 'привыкли', 'всюду', 'соваться']\n",
      "['я', 'пишу', 'для', 'себя', 'а', 'печатаю', 'для', 'денег']\n",
      "['в', 'некотором', 'азиатском', 'народе', 'мужчины', 'каждый', 'день', 'восстав', 'от', 'сна', 'благодарят', 'бога', 'создавшего', 'их', 'не', 'женщинами']\n",
      "['разве', 'у', 'хорошеньких', 'женщин', 'должен', 'быть', 'характер']\n",
      "['европа', 'в', 'отношении', 'к', 'россии', 'всегда', 'была', 'столь', 'же', 'невежественна', 'как', 'и', 'неблагодарна']\n"
     ]
    }
   ],
   "source": [
    "for s, lang in test:\n",
    "    print(process_sentence(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create words vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "for sentence, _ in train + test:\n",
    "    for word in process_sentence(sentence):\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(vocabulary)\n",
    "output_size = len(target_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform sentense into \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence):\n",
    "    tokens = process_sentence(sentence)\n",
    "    vector = [0] * input_size\n",
    "    for t in tokens:\n",
    "        vector[vocabulary[t]] += 1\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple log regression with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.log_softmax(self.linear(x), 1)\n",
    "    \n",
    "model = LogReg(input_size, output_size)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    wrong = []\n",
    "    with torch.no_grad(): \n",
    "        for idx, (sentence, lang) in enumerate(test):\n",
    "            input_value = torch.tensor([sentence_to_vector(sentence)]).float()\n",
    "            target_value = torch.tensor([target_values[lang]])\n",
    "            predict = model(input_value)\n",
    "            predict_lang = targets[predict.max(1)[1].item()]\n",
    "            \n",
    "            if lang != predict_lang:\n",
    "                wrong.append((sentence, lang, predict, predict_lang))\n",
    "            \n",
    "            print(idx, sentence)\n",
    "            print(f\"probabilities: {predict.exp().tolist()}\")\n",
    "            print(f\"real: {lang}\")\n",
    "            print(f\"predict: {predict_lang}\")\n",
    "            print()\n",
    "            \n",
    "    return wrong\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate before train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Так от, бач, живу, учусь, нікому не кланяюсь і нікого не боюсь, окроме Бога.\n",
      "probabilities: [[0.5211635828018188, 0.47883638739585876]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "1 Коли мене неволя і горе не побороло, то сам я не звалюся.\n",
      "probabilities: [[0.5938897132873535, 0.4061102867126465]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "2 Пустив я їх у люди, а до ції пори ще ніхто й спасибі не сказав.\n",
      "probabilities: [[0.5119473338127136, 0.488052636384964]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "3 Бачиш, у мене давно вже думка заворушилась перевести його, те слово, на наш милий, на наш любий український язик.\n",
      "probabilities: [[0.5188233852386475, 0.48117661476135254]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "4 Я читаю його без вивчення, щодня і щогодини.\n",
      "probabilities: [[0.51186603307724, 0.4881339967250824]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "5 Они нужны в некоторых только случаях, но и тут можно без них обойтись, а они привыкли всюду соваться.\n",
      "probabilities: [[0.5099589824676514, 0.4900410771369934]]\n",
      "real: ru\n",
      "predict: ua\n",
      "\n",
      "6 Я пишу для себя, а печатаю для денег.\n",
      "probabilities: [[0.4986094534397125, 0.5013905763626099]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "7 В некотором азиатском народе мужчины каждый день, восстав от сна, благодарят Бога, создавшего их не женщинами.\n",
      "probabilities: [[0.5975937247276306, 0.4024063050746918]]\n",
      "real: ru\n",
      "predict: ua\n",
      "\n",
      "8 Разве у хорошеньких женщин должен быть характер?\n",
      "probabilities: [[0.49574020504951477, 0.5042597651481628]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "9 Европа в отношении к России всегда была столь же невежественна, как и неблагодарна.\n",
      "probabilities: [[0.5245638489723206, 0.47543618083000183]]\n",
      "real: ru\n",
      "predict: ua\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "\n",
    "for e in range(epoch):\n",
    "    for sentence, lang in train:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_value = torch.tensor([sentence_to_vector(sentence)]).float()\n",
    "        target_value = torch.tensor([target_values[lang]])\n",
    "        \n",
    "        out = model(input_value)\n",
    "        loss = criterion(out, target_value)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model results and save wrong predics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Так от, бач, живу, учусь, нікому не кланяюсь і нікого не боюсь, окроме Бога.\n",
      "probabilities: [[0.942940890789032, 0.05705922096967697]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "1 Коли мене неволя і горе не побороло, то сам я не звалюся.\n",
      "probabilities: [[0.9585253000259399, 0.04147466644644737]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "2 Пустив я їх у люди, а до ції пори ще ніхто й спасибі не сказав.\n",
      "probabilities: [[0.8110288977622986, 0.18897107243537903]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "3 Бачиш, у мене давно вже думка заворушилась перевести його, те слово, на наш милий, на наш любий український язик.\n",
      "probabilities: [[0.4064921736717224, 0.5935078263282776]]\n",
      "real: ua\n",
      "predict: ru\n",
      "\n",
      "4 Я читаю його без вивчення, щодня і щогодини.\n",
      "probabilities: [[0.795758068561554, 0.20424190163612366]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "5 Они нужны в некоторых только случаях, но и тут можно без них обойтись, а они привыкли всюду соваться.\n",
      "probabilities: [[0.07637488842010498, 0.9236250519752502]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "6 Я пишу для себя, а печатаю для денег.\n",
      "probabilities: [[0.36269134283065796, 0.6373087167739868]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "7 В некотором азиатском народе мужчины каждый день, восстав от сна, благодарят Бога, создавшего их не женщинами.\n",
      "probabilities: [[0.5651276111602783, 0.4348723888397217]]\n",
      "real: ru\n",
      "predict: ua\n",
      "\n",
      "8 Разве у хорошеньких женщин должен быть характер?\n",
      "probabilities: [[0.3517642617225647, 0.6482357382774353]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "9 Европа в отношении к России всегда была столь же невежественна, как и неблагодарна.\n",
      "probabilities: [[0.06441900879144669, 0.9355809688568115]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wrong = evaluate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results understanding\n",
    "- What are the most influence words for each language?\n",
    "- Why we get wrong resluts on test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA\n",
      "[('і', 0.7957349419593811), ('мати', 0.46213188767433167), ('й', 0.37297990918159485), ('кайданами', 0.32162174582481384), ('не', 0.31822913885116577), ('торгують', 0.31541237235069275), ('обніміте', 0.2739221155643463), ('правдою', 0.2549022138118744), ('ми', 0.25034299492836), ('але', 0.24698905646800995)]\n",
      "\n",
      "RU\n",
      "[('и', 0.6365033984184265), ('точность', 0.28323057293891907), ('поваров', 0.2691304385662079), ('что', 0.25943639874458313), ('поэзия', 0.24396340548992157), ('вежливость', 0.23372700810432434), ('будет', 0.22419758141040802), ('съесть', 0.2167694866657257), ('кто', 0.2146964818239212), ('своей', 0.21413546800613403)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weigths = next(model.linear.parameters())\n",
    "most_important_len = 10\n",
    "words_importance = {}\n",
    "for word, idx in vocabulary.items():\n",
    "    words_importance[word] = {\n",
    "        \"lang\": targets[weigths[:, idx].argmax().item()],\n",
    "        \"importance\": weigths[:, idx].max().item()\n",
    "    }\n",
    "\n",
    "for lang in targets:\n",
    "    print(lang.upper())\n",
    "    lang_words = list(filter(lambda v: v[1][\"lang\"] == lang, words_importance.items()))\n",
    "    most_important = sorted(lang_words, key=lambda v: v[1][\"importance\"], reverse=True)\n",
    "    print(list(map(lambda v: (v[0], v[1][\"importance\"]), most_important[:most_important_len])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бачиш, у мене давно вже думка заворушилась перевести його, те слово, на наш милий, на наш любий український язик.\n",
      "probabilities: [[0.4064921736717224, 0.5935078263282776]]\n",
      "real: ua\n",
      "predict: ru\n",
      "у {'lang': 'ua', 'importance': 0.13456518948078156}\n",
      "на {'lang': 'ru', 'importance': 0.08325985819101334}\n",
      "на {'lang': 'ru', 'importance': 0.08325985819101334}\n",
      "слово {'lang': 'ua', 'importance': 0.05775173008441925}\n",
      "його {'lang': 'ua', 'importance': 0.04947809502482414}\n",
      "язик {'lang': 'ua', 'importance': 0.049182742834091187}\n",
      "давно {'lang': 'ua', 'importance': 0.046600326895713806}\n",
      "бачиш {'lang': 'ru', 'importance': 0.045283906161785126}\n",
      "думка {'lang': 'ua', 'importance': 0.0439450666308403}\n",
      "заворушилась {'lang': 'ru', 'importance': 0.03568706661462784}\n",
      "український {'lang': 'ua', 'importance': 0.032685257494449615}\n",
      "перевести {'lang': 'ru', 'importance': 0.030952930450439453}\n",
      "любий {'lang': 'ru', 'importance': 0.025579750537872314}\n",
      "вже {'lang': 'ru', 'importance': 0.0013688430190086365}\n",
      "те {'lang': 'ru', 'importance': -0.012391574680805206}\n",
      "милий {'lang': 'ru', 'importance': -0.012836601585149765}\n",
      "мене {'lang': 'ru', 'importance': -0.014415424317121506}\n",
      "наш {'lang': 'ru', 'importance': -0.01689394935965538}\n",
      "наш {'lang': 'ru', 'importance': -0.01689394935965538}\n",
      "\n",
      "В некотором азиатском народе мужчины каждый день, восстав от сна, благодарят Бога, создавшего их не женщинами.\n",
      "probabilities: [[0.5651276111602783, 0.4348723888397217]]\n",
      "real: ru\n",
      "predict: ua\n",
      "не {'lang': 'ua', 'importance': 0.31822913885116577}\n",
      "в {'lang': 'ru', 'importance': 0.20113901793956757}\n",
      "азиатском {'lang': 'ua', 'importance': 0.053089678287506104}\n",
      "сна {'lang': 'ua', 'importance': 0.05005277693271637}\n",
      "бога {'lang': 'ua', 'importance': 0.04413307458162308}\n",
      "мужчины {'lang': 'ua', 'importance': 0.027944646775722504}\n",
      "день {'lang': 'ru', 'importance': 0.018978215754032135}\n",
      "благодарят {'lang': 'ua', 'importance': 0.013414442539215088}\n",
      "народе {'lang': 'ua', 'importance': 0.012803293764591217}\n",
      "их {'lang': 'ua', 'importance': 0.006005823612213135}\n",
      "восстав {'lang': 'ua', 'importance': 0.0005790144205093384}\n",
      "некотором {'lang': 'ru', 'importance': -0.002497117966413498}\n",
      "женщинами {'lang': 'ua', 'importance': -0.002548612654209137}\n",
      "от {'lang': 'ru', 'importance': -0.010794807225465775}\n",
      "создавшего {'lang': 'ru', 'importance': -0.03366877883672714}\n",
      "каждый {'lang': 'ua', 'importance': -0.04308367520570755}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence, lang, predict, predict_lang in wrong:\n",
    "    print(sentence)\n",
    "    print(f\"probabilities: {predict.exp().tolist()}\")\n",
    "    print(f\"real: {lang}\")\n",
    "    print(f\"predict: {predict_lang}\")\n",
    "    tokens = process_sentence(sentence)\n",
    "    tokens = sorted(tokens, key=lambda t: words_importance[t][\"importance\"], reverse=True)\n",
    "    for t in tokens:\n",
    "        print(t, words_importance[t])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
