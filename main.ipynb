{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic classifier over bag of words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect dataset\n",
    "Resources:\n",
    "- [Wikiquote: Taras Hryhorovych Shevchenko](https://uk.wikiquote.org/wiki/%D0%A8%D0%B5%D0%B2%D1%87%D0%B5%D0%BD%D0%BA%D0%BE_%D0%A2%D0%B0%D1%80%D0%B0%D1%81_%D0%93%D1%80%D0%B8%D0%B3%D0%BE%D1%80%D0%BE%D0%B2%D0%B8%D1%87)\n",
    "- [Wikiquote: Aleksandr Sergeyevich Pushkin](https://ru.wikiquote.org/wiki/%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80_%D0%A1%D0%B5%D1%80%D0%B3%D0%B5%D0%B5%D0%B2%D0%B8%D1%87_%D0%9F%D1%83%D1%88%D0%BA%D0%B8%D0%BD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    (\"В своїй хаті своя й правда, і сила, і воля.\", \"ua\"),\n",
    "    (\"Якби ви вчились так, як треба, то й мудрость би була своя.\", \"ua\"),\n",
    "    (\"Учітесь, читайте, і чужому научайтесь, й свого не цурайтесь.\", \"ua\"),\n",
    "    (\"Обніміте ж, брати мої, найменшого брата.\", \"ua\"),\n",
    "    (\"І на оновленій землі врага не буде, супостата, а буде син, і буде мати, і будуть люде на землі.\", \"ua\"),\n",
    "    (\"І ми не ми, і я не я.\", \"ua\"),\n",
    "    (\"І премудрих немудрі одурять.\", \"ua\"),\n",
    "    (\"Кайданами міняються, правдою торгують.\", \"ua\"),\n",
    "    (\"Караюсь, мучуся… але не каюсь.\", \"ua\"),\n",
    "    (\"Ми просто йшли; у нас нема зерна неправди за собою.\", \"ua\"),\n",
    "    (\"Велике щастя буть вольним чоловіком: робиш, що хочеш, ніхто тебе не спинить.\", \"ua\"),\n",
    "    (\"Це правда, що окроме Бога і чорта в душі нашій єсть ще щось таке, таке страшне, що аж холод іде по серцеві, як хоч трошки його розкриєш\", \"ua\"),\n",
    "    (\"Хто не журиться, не плаче, то той ніколи й не радіє.\", \"ua\"),\n",
    "    (\"Лучше любить і робить, аніж писать і говорить.\", \"ua\"),\n",
    "    (\"Мати, всюди однакова мати.\", \"ua\"),\n",
    "    \n",
    "    \n",
    "    \n",
    "    (\"Вдохновение — это умение приводить себя в рабочее состояние.\", \"ru\"),\n",
    "    (\"Во всяком случае, в аду будет много хорошеньких, там можно будет играть в шарады.\", \"ru\"),\n",
    "    (\"Должно стараться иметь большинство на своей стороне: не оскорбляйте же глупцов.\", \"ru\"),\n",
    "    (\"Желудок просвещенного человека имеет лучшие качества доброго сердца: чувствительность и благодарность.\", \"ru\"),\n",
    "    (\"Зависть — сестра соревнования, следственно из хорошего роду.\", \"ru\"),\n",
    "    (\"Зачем кусать нам груди кормилицы нашей; потому что зубки прорезались?\", \"ru\"),\n",
    "    (\"Злы только дураки и дети.\", \"ru\"),\n",
    "    (\"Не откладывай до ужина того, что можешь съесть за обедом.\", \"ru\"),\n",
    "    (\"Не приведи Бог видеть русский бунт, бессмысленный и беспощадный!\", \"ru\"),\n",
    "    (\"Нет ничего безвкуснее долготерпения и самоотверженности.\", \"ru\"),\n",
    "    (\"Первая любовь всегда является делом чувствительности.\", \"ru\"),\n",
    "    (\"Поэзия выше нравственности — или по крайней мере совсем иное дело.\", \"ru\"),\n",
    "    (\"Поэзия, прости господи, должна быть глуповата.\", \"ru\"),\n",
    "    (\"Разберись, кто прав, кто виноват, да обоих и накажи.\", \"ru\"),\n",
    "    (\"Точность — вежливость поваров.\", \"ru\"),\n",
    "]\n",
    "\n",
    "test = [\n",
    "    (\"Так от, бач, живу, учусь, нікому не кланяюсь і нікого не боюсь, окроме Бога.\", \"ua\"),\n",
    "    (\"Коли мене неволя і горе не побороло, то сам я не звалюся.\", \"ua\"),\n",
    "    (\"Пустив я їх у люди, а до ції пори ще ніхто й спасибі не сказав.\", \"ua\"),\n",
    "    (\"Бачиш, у мене давно вже думка заворушилась перевести його, те слово, на наш милий, на наш любий український язик.\", \"ua\"),\n",
    "    (\"Я читаю його без вивчення, щодня і щогодини.\", \"ua\"),\n",
    "    \n",
    "    (\"Они нужны в некоторых только случаях, но и тут можно без них обойтись, а они привыкли всюду соваться.\", \"ru\"),\n",
    "    (\"Я пишу для себя, а печатаю для денег.\", \"ru\"),\n",
    "    (\"В некотором азиатском народе мужчины каждый день, восстав от сна, благодарят Бога, создавшего их не женщинами.\", \"ru\"),\n",
    "    (\"Разве у хорошеньких женщин должен быть характер?\", \"ru\"),\n",
    "    (\"Европа в отношении к России всегда была столь же невежественна, как и неблагодарна.\", \"ru\"),\n",
    "]\n",
    "\n",
    "targets = [\"ua\", \"ru\"]\n",
    "target_values = {l: i for i, l in enumerate(targets)}\n",
    "random.shuffle(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r\"[^\\w ]\", \"\", sentence)\n",
    "    tokens = sentence.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['так', 'от', 'бач', 'живу', 'учусь', 'нікому', 'не', 'кланяюсь', 'і', 'нікого', 'не', 'боюсь', 'окроме', 'бога']\n",
      "['коли', 'мене', 'неволя', 'і', 'горе', 'не', 'побороло', 'то', 'сам', 'я', 'не', 'звалюся']\n",
      "['пустив', 'я', 'їх', 'у', 'люди', 'а', 'до', 'ції', 'пори', 'ще', 'ніхто', 'й', 'спасибі', 'не', 'сказав']\n",
      "['бачиш', 'у', 'мене', 'давно', 'вже', 'думка', 'заворушилась', 'перевести', 'його', 'те', 'слово', 'на', 'наш', 'милий', 'на', 'наш', 'любий', 'український', 'язик']\n",
      "['я', 'читаю', 'його', 'без', 'вивчення', 'щодня', 'і', 'щогодини']\n",
      "['они', 'нужны', 'в', 'некоторых', 'только', 'случаях', 'но', 'и', 'тут', 'можно', 'без', 'них', 'обойтись', 'а', 'они', 'привыкли', 'всюду', 'соваться']\n",
      "['я', 'пишу', 'для', 'себя', 'а', 'печатаю', 'для', 'денег']\n",
      "['в', 'некотором', 'азиатском', 'народе', 'мужчины', 'каждый', 'день', 'восстав', 'от', 'сна', 'благодарят', 'бога', 'создавшего', 'их', 'не', 'женщинами']\n",
      "['разве', 'у', 'хорошеньких', 'женщин', 'должен', 'быть', 'характер']\n",
      "['европа', 'в', 'отношении', 'к', 'россии', 'всегда', 'была', 'столь', 'же', 'невежественна', 'как', 'и', 'неблагодарна']\n"
     ]
    }
   ],
   "source": [
    "for s, lang in test:\n",
    "    print(process_sentence(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create words vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "for sentence, _ in train + test:\n",
    "    for word in process_sentence(sentence):\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(vocabulary)\n",
    "output_size = len(target_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform sentense into \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence):\n",
    "    tokens = process_sentence(sentence)\n",
    "    vector = [0] * input_size\n",
    "    for t in tokens:\n",
    "        vector[vocabulary[t]] += 1\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple log regression with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.softmax(self.linear(x), 1)\n",
    "    \n",
    "model = LogReg(input_size, output_size)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    wrong = []\n",
    "    with torch.no_grad(): \n",
    "        for idx, (sentence, lang) in enumerate(test):\n",
    "            input_value = torch.tensor([sentence_to_vector(sentence)]).float()\n",
    "            target_value = torch.tensor([target_values[lang]])\n",
    "            predict = model(input_value)\n",
    "            predict_lang = targets[predict.max(1)[1].item()]\n",
    "            \n",
    "            if lang != predict_lang:\n",
    "                wrong.append((sentence, lang, predict, predict_lang))\n",
    "            \n",
    "            print(idx, sentence)\n",
    "            print(f\"probabilities: {predict.tolist()}\")\n",
    "            print(f\"real: {lang}\")\n",
    "            print(f\"predict: {predict_lang}\")\n",
    "            print()\n",
    "            \n",
    "    return wrong\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate before train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Так от, бач, живу, учусь, нікому не кланяюсь і нікого не боюсь, окроме Бога.\n",
      "probabilities: [[0.49442726373672485, 0.5055727362632751]]\n",
      "real: ua\n",
      "predict: ru\n",
      "\n",
      "1 Коли мене неволя і горе не побороло, то сам я не звалюся.\n",
      "probabilities: [[0.48034000396728516, 0.5196600556373596]]\n",
      "real: ua\n",
      "predict: ru\n",
      "\n",
      "2 Пустив я їх у люди, а до ції пори ще ніхто й спасибі не сказав.\n",
      "probabilities: [[0.46988657116889954, 0.5301134586334229]]\n",
      "real: ua\n",
      "predict: ru\n",
      "\n",
      "3 Бачиш, у мене давно вже думка заворушилась перевести його, те слово, на наш милий, на наш любий український язик.\n",
      "probabilities: [[0.5766773223876953, 0.42332273721694946]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "4 Я читаю його без вивчення, щодня і щогодини.\n",
      "probabilities: [[0.48903608322143555, 0.5109638571739197]]\n",
      "real: ua\n",
      "predict: ru\n",
      "\n",
      "5 Они нужны в некоторых только случаях, но и тут можно без них обойтись, а они привыкли всюду соваться.\n",
      "probabilities: [[0.5373398661613464, 0.46266019344329834]]\n",
      "real: ru\n",
      "predict: ua\n",
      "\n",
      "6 Я пишу для себя, а печатаю для денег.\n",
      "probabilities: [[0.5368438959121704, 0.4631561040878296]]\n",
      "real: ru\n",
      "predict: ua\n",
      "\n",
      "7 В некотором азиатском народе мужчины каждый день, восстав от сна, благодарят Бога, создавшего их не женщинами.\n",
      "probabilities: [[0.5096891522407532, 0.4903108477592468]]\n",
      "real: ru\n",
      "predict: ua\n",
      "\n",
      "8 Разве у хорошеньких женщин должен быть характер?\n",
      "probabilities: [[0.47402068972587585, 0.5259793400764465]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "9 Европа в отношении к России всегда была столь же невежественна, как и неблагодарна.\n",
      "probabilities: [[0.4760478436946869, 0.5239521265029907]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "\n",
    "for e in range(epoch):\n",
    "    for sentence, lang in train:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_value = torch.tensor([sentence_to_vector(sentence)]).float()\n",
    "        target_value = torch.tensor([target_values[lang]])\n",
    "        \n",
    "        out = model(input_value)\n",
    "        loss = criterion(out, target_value)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model results and save wrong predics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Так от, бач, живу, учусь, нікому не кланяюсь і нікого не боюсь, окроме Бога.\n",
      "probabilities: [[0.9433287978172302, 0.056671142578125]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "1 Коли мене неволя і горе не побороло, то сам я не звалюся.\n",
      "probabilities: [[0.9469779133796692, 0.053022027015686035]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "2 Пустив я їх у люди, а до ції пори ще ніхто й спасибі не сказав.\n",
      "probabilities: [[0.7978948950767517, 0.20210511982440948]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "3 Бачиш, у мене давно вже думка заворушилась перевести його, те слово, на наш милий, на наш любий український язик.\n",
      "probabilities: [[0.4830685257911682, 0.5169314742088318]]\n",
      "real: ua\n",
      "predict: ru\n",
      "\n",
      "4 Я читаю його без вивчення, щодня і щогодини.\n",
      "probabilities: [[0.7895163297653198, 0.21048370003700256]]\n",
      "real: ua\n",
      "predict: ua\n",
      "\n",
      "5 Они нужны в некоторых только случаях, но и тут можно без них обойтись, а они привыкли всюду соваться.\n",
      "probabilities: [[0.10279274731874466, 0.8972072601318359]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "6 Я пишу для себя, а печатаю для денег.\n",
      "probabilities: [[0.4220646023750305, 0.5779353976249695]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "7 В некотором азиатском народе мужчины каждый день, восстав от сна, благодарят Бога, создавшего их не женщинами.\n",
      "probabilities: [[0.5073200464248657, 0.4926799535751343]]\n",
      "real: ru\n",
      "predict: ua\n",
      "\n",
      "8 Разве у хорошеньких женщин должен быть характер?\n",
      "probabilities: [[0.34598007798194885, 0.6540199518203735]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n",
      "9 Европа в отношении к России всегда была столь же невежественна, как и неблагодарна.\n",
      "probabilities: [[0.06741107255220413, 0.9325889945030212]]\n",
      "real: ru\n",
      "predict: ru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wrong = evaluate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results understanding\n",
    "- What are the most influence words for each language?\n",
    "- Why we get wrong resluts on test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA\n",
      "[('і', 0.7483457326889038), ('мати', 0.4274558424949646), ('не', 0.31153225898742676), ('й', 0.3012298345565796), ('ми', 0.27373555302619934), ('ж', 0.24648517370224), ('кайданами', 0.2414771318435669), ('правдою', 0.23094195127487183), ('то', 0.22950570285320282), ('караюсь', 0.22051571309566498)]\n",
      "\n",
      "RU\n",
      "[('и', 0.5791085362434387), ('вежливость', 0.2346676141023636), ('поэзия', 0.22842636704444885), ('что', 0.2220650464296341), ('будет', 0.21561896800994873), ('же', 0.20251421630382538), ('ужина', 0.2002698928117752), ('умение', 0.19408069550991058), ('поваров', 0.19223856925964355), ('кто', 0.18930502235889435)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weigths = next(model.linear.parameters())\n",
    "most_important_len = 10\n",
    "words_importance = {}\n",
    "for word, idx in vocabulary.items():\n",
    "    words_importance[word] = {\n",
    "        \"lang\": targets[weigths[:, idx].argmax().item()],\n",
    "        \"importance\": weigths[:, idx].max().item()\n",
    "    }\n",
    "\n",
    "for lang in targets:\n",
    "    print(lang.upper())\n",
    "    lang_words = list(filter(lambda v: v[1][\"lang\"] == lang, words_importance.items()))\n",
    "    most_important = sorted(lang_words, key=lambda v: v[1][\"importance\"], reverse=True)\n",
    "    print(list(map(lambda v: (v[0], v[1][\"importance\"]), most_important[:most_important_len])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бачиш, у мене давно вже думка заворушилась перевести його, те слово, на наш милий, на наш любий український язик.\n",
      "probabilities: [[0.4830685257911682, 0.5169314742088318]]\n",
      "real: ua\n",
      "predict: ru\n",
      "у {'lang': 'ua', 'importance': 0.17231599986553192}\n",
      "на {'lang': 'ru', 'importance': 0.055308520793914795}\n",
      "на {'lang': 'ru', 'importance': 0.055308520793914795}\n",
      "український {'lang': 'ru', 'importance': 0.05167703330516815}\n",
      "слово {'lang': 'ua', 'importance': 0.05153817683458328}\n",
      "його {'lang': 'ua', 'importance': 0.04777233675122261}\n",
      "перевести {'lang': 'ru', 'importance': 0.04253116995096207}\n",
      "любий {'lang': 'ru', 'importance': 0.04146210849285126}\n",
      "наш {'lang': 'ua', 'importance': 0.03705056756734848}\n",
      "наш {'lang': 'ua', 'importance': 0.03705056756734848}\n",
      "милий {'lang': 'ua', 'importance': 0.0234699547290802}\n",
      "думка {'lang': 'ua', 'importance': 0.01854587346315384}\n",
      "те {'lang': 'ru', 'importance': 7.054954767227173e-05}\n",
      "язик {'lang': 'ru', 'importance': -7.581710815429688e-05}\n",
      "бачиш {'lang': 'ua', 'importance': -0.004954814910888672}\n",
      "вже {'lang': 'ua', 'importance': -0.004996448755264282}\n",
      "мене {'lang': 'ru', 'importance': -0.008537162095308304}\n",
      "заворушилась {'lang': 'ua', 'importance': -0.028488025069236755}\n",
      "давно {'lang': 'ua', 'importance': -0.02902735210955143}\n",
      "\n",
      "В некотором азиатском народе мужчины каждый день, восстав от сна, благодарят Бога, создавшего их не женщинами.\n",
      "probabilities: [[0.5073200464248657, 0.4926799535751343]]\n",
      "real: ru\n",
      "predict: ua\n",
      "не {'lang': 'ua', 'importance': 0.31153225898742676}\n",
      "в {'lang': 'ru', 'importance': 0.15633375942707062}\n",
      "бога {'lang': 'ua', 'importance': 0.09482219815254211}\n",
      "каждый {'lang': 'ru', 'importance': 0.034952662885189056}\n",
      "их {'lang': 'ru', 'importance': 0.031005673110485077}\n",
      "день {'lang': 'ua', 'importance': 0.03095681220293045}\n",
      "сна {'lang': 'ua', 'importance': 0.0156865194439888}\n",
      "женщинами {'lang': 'ru', 'importance': 0.015376262366771698}\n",
      "народе {'lang': 'ru', 'importance': 0.012765884399414062}\n",
      "от {'lang': 'ru', 'importance': -0.007349390536546707}\n",
      "благодарят {'lang': 'ru', 'importance': -0.011255569756031036}\n",
      "азиатском {'lang': 'ua', 'importance': -0.014588441699743271}\n",
      "создавшего {'lang': 'ua', 'importance': -0.015392933040857315}\n",
      "мужчины {'lang': 'ua', 'importance': -0.015417102724313736}\n",
      "некотором {'lang': 'ru', 'importance': -0.028080027550458908}\n",
      "восстав {'lang': 'ua', 'importance': -0.028574302792549133}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence, lang, predict, predict_lang in wrong:\n",
    "    print(sentence)\n",
    "    print(f\"probabilities: {predict.tolist()}\")\n",
    "    print(f\"real: {lang}\")\n",
    "    print(f\"predict: {predict_lang}\")\n",
    "    tokens = process_sentence(sentence)\n",
    "    tokens = sorted(tokens, key=lambda t: words_importance[t][\"importance\"], reverse=True)\n",
    "    for t in tokens:\n",
    "        print(t, words_importance[t])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
